{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll6mUpDkZEIg"
      },
      "source": [
        "# **Generic**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-KH86QFZEIh"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from scipy.signal import find_peaks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLkqw1BIZEIh"
      },
      "source": [
        "**Crop and Display Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX0T5_uaZEIi"
      },
      "outputs": [],
      "source": [
        "def crop_barcode3(img):\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv.findContours(img, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Assume the largest contour corresponds to the barcode\n",
        "    largest_contour = max(contours, key=cv.contourArea)\n",
        "    largest_contour_area = cv.contourArea(largest_contour)\n",
        "\n",
        "    # Initialize variables to store the leftmost and rightmost contours\n",
        "    leftmost_contour = None\n",
        "    rightmost_contour = None\n",
        "    x_min = float('inf')\n",
        "    x_max = float('-inf')\n",
        "\n",
        "    # Find the leftmost and rightmost contours\n",
        "    for contour in contours:\n",
        "        contour_area = cv.contourArea(contour)\n",
        "        if contour_area >= 0.05 * largest_contour_area:  # Check if the contour area is significant\n",
        "            x, _, w, _ = cv.boundingRect(contour)\n",
        "            if x < x_min:\n",
        "                x_min = x\n",
        "                leftmost_contour = contour\n",
        "            if x > x_max:  # Use x to get the far-right edge of the contour\n",
        "                x_max = x\n",
        "                rightmost_contour = contour\n",
        "\n",
        "    x_min, _, _, _ = cv.boundingRect(leftmost_contour)\n",
        "    x_max, _, w, _ = cv.boundingRect(rightmost_contour)\n",
        "\n",
        "    # Get the vertical limits from the largest contour\n",
        "    _, y, _, h = cv.boundingRect(largest_contour)\n",
        "\n",
        "    # Crop the image so that only the barcode is visible\n",
        "    cropped_img = img[y:y + h, x_min:x_max+w]\n",
        "\n",
        "    # Draw all contours in red\n",
        "    contour_img = cv.cvtColor(cv.bitwise_not(img), cv.COLOR_GRAY2BGR)  # Convert to BGR for colored drawing\n",
        "    cv.drawContours(contour_img, contours, -1, (255, 0, 0), 4)  # Draw all contours in red\n",
        "\n",
        "    return cropped_img, contour_img\n",
        "\n",
        "def display_image(img, title):\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(title)\n",
        "    # Draw border around the image\n",
        "    plt.gca().add_patch(plt.Rectangle((0, 0), img.shape[1], img.shape[0], fill=None, edgecolor='red', linewidth=1))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWsL5Qo2ZEIi"
      },
      "source": [
        "**Read Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsh7Q_CkZEIi",
        "outputId": "e1456c8b-5d16-48e0-d5f6-add30c4abff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select the number of the image you want to load:\n",
            "1: 01 - lol easy.jpg\n",
            "2: 02 - still easy.jpg\n",
            "3: 03 - eda ya3am ew3a soba3ak mathazarsh.jpg\n",
            "4: 04 - fen el nadara.jpg\n",
            "5: 05 - meen taffa el nour!!!.jpg\n",
            "6: 06 - meen fata7 el nour 333eenaaayy.jpg\n",
            "7: 07 - mal7 w felfel.jpg\n",
            "8: 08 - compresso espresso.jpg\n",
            "9: 09 - e3del el soora ya3ammm.jpg\n",
            "10: 10 - wen el kontraastttt.jpg\n",
            "11: 11 - bayza 5ales di bsara7a.jpg\n",
            "12: Screenshot 2024-12-12 231530.png\n",
            "Enter the image number: 1\n"
          ]
        }
      ],
      "source": [
        "import cv2 as cv\n",
        "\n",
        "# Prompt user to select the image number\n",
        "print(\"Select the number of the image you want to load:\")\n",
        "print(\"1: 01 - lol easy.jpg\")\n",
        "print(\"2: 02 - still easy.jpg\")\n",
        "print(\"3: 03 - eda ya3am ew3a soba3ak mathazarsh.jpg\")\n",
        "print(\"4: 04 - fen el nadara.jpg\")\n",
        "print(\"5: 05 - meen taffa el nour!!!.jpg\")\n",
        "print(\"6: 06 - meen fata7 el nour 333eenaaayy.jpg\")\n",
        "print(\"7: 07 - mal7 w felfel.jpg\")\n",
        "print(\"8: 08 - compresso espresso.jpg\")\n",
        "print(\"9: 09 - e3del el soora ya3ammm.jpg\")\n",
        "print(\"10: 10 - wen el kontraastttt.jpg\")\n",
        "print(\"11: 11 - bayza 5ales di bsara7a.jpg\")\n",
        "print(\"12: Screenshot 2024-12-12 231530.png\")\n",
        "\n",
        "image_number = int(input(\"Enter the image number: \"))\n",
        "\n",
        "if image_number == 1:\n",
        "    img = cv.imread('01 - lol easy.jpg')\n",
        "elif image_number == 2:\n",
        "    img = cv.imread('02 - still easy.jpg')\n",
        "elif image_number == 3:\n",
        "    img = cv.imread('03 - eda ya3am ew3a soba3ak mathazarsh.jpg')\n",
        "elif image_number == 4:\n",
        "    img = cv.imread('04 - fen el nadara.jpg')\n",
        "elif image_number == 5:\n",
        "    img = cv.imread('05 - meen taffa el nour!!!.jpg')\n",
        "elif image_number == 6:\n",
        "    img = cv.imread('06 - meen fata7 el nour 333eenaaayy.jpg')\n",
        "elif image_number == 7:\n",
        "    img = cv.imread('07 - mal7 w felfel.jpg')\n",
        "elif image_number == 8:\n",
        "    img = cv.imread('08 - compresso espresso.jpg')\n",
        "elif image_number == 9:\n",
        "    img = cv.imread('09 - e3del el soora ya3ammm.jpg')\n",
        "elif image_number == 10:\n",
        "    img = cv.imread('10 - wen el kontraastttt.jpg')\n",
        "elif image_number == 11:\n",
        "    img = cv.imread('11 - bayza 5ales di bsara7a.jpg')\n",
        "elif image_number == 12:\n",
        "    img = cv.imread('Samples/Screenshot 2024-12-12 231530.png')\n",
        "else:\n",
        "    print(\"Invalid image number. Please try again.\")\n",
        "    img = None\n",
        "\n",
        "# Display the loaded image\n",
        "if img is not None:\n",
        "    display_image(cv.cvtColor(img, cv.COLOR_BGR2RGB), \"Original Image\")\n",
        "\n",
        "\n",
        "#Utility Masks, might need for later\n",
        "\n",
        "# Rectangle Mask\n",
        "def generate_rectangle_mask(mask_dimensions, top_left, bottom_right):\n",
        "    mask = np.zeros(mask_dimensions, dtype=np.uint8)\n",
        "    return cv.rectangle(mask, top_left, bottom_right, 255, -1)\n",
        "\n",
        "\n",
        "def generate_circle_mask(mask_dimensions, mask_radius):\n",
        "    circle_mask = np.zeros(mask_dimensions)\n",
        "    center_y = circle_mask.shape[0] // 2\n",
        "    center_x = circle_mask.shape[1] // 2\n",
        "    return cv.circle(circle_mask, (center_x, center_y), mask_radius, (255, 255, 255), -1).astype(np.uint8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plCb68rEZEIj"
      },
      "source": [
        "**Isolate Barcode (Test Case 3)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "5FIhfbCBZEIj",
        "outputId": "273beede-98c3-488e-e4dd-7c3faefaad7c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'astype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-adf85ad229c5>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Isolate the barcode with white background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0misolated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misolate_barcode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misolated_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Isolated Barcode (White Background)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-adf85ad229c5>\u001b[0m in \u001b[0;36misolate_barcode\u001b[0;34m(image, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Convert image to float for better processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Extract R, G, B channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'astype'"
          ]
        }
      ],
      "source": [
        "def isolate_barcode(image, threshold=10):\n",
        "\n",
        "    # Convert image to float for better processing\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    # Extract R, G, B channels\n",
        "    B, G, R = cv.split(image)\n",
        "\n",
        "    # Compute absolute differences between channels\n",
        "    diff_rg = np.abs(R - G)\n",
        "    diff_rb = np.abs(R - B)\n",
        "    diff_gb = np.abs(G - B)\n",
        "\n",
        "    # Create a mask where differences are below the threshold (grayscale condition)\n",
        "    mask = (diff_rg < threshold) & (diff_rb < threshold) & (diff_gb < threshold)\n",
        "\n",
        "    # Convert mask to binary (0 and 255)\n",
        "    mask = mask.astype(np.uint8) * 255\n",
        "\n",
        "    # Create a white canvas for the background\n",
        "    white_canvas = np.ones_like(image, dtype=np.uint8) * 255  # White background\n",
        "\n",
        "    # Apply mask to the original image to keep only grayscale pixels\n",
        "    isolated_image = cv.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    # Invert the mask to fill the background with white\n",
        "    inverse_mask = cv.bitwise_not(mask)\n",
        "    isolated_image += cv.bitwise_and(white_canvas, white_canvas, mask=inverse_mask)\n",
        "\n",
        "    return isolated_image.astype(np.uint8)\n",
        "\n",
        "# Isolate the barcode with white background\n",
        "isolated_image = isolate_barcode(img, threshold=10)\n",
        "\n",
        "display_image(cv.cvtColor(isolated_image, cv.COLOR_BGR2RGB), \"Isolated Barcode (White Background)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r7N_5FlZEIj"
      },
      "source": [
        "**Convert to Greyscale**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLlbZ_PwZEIj"
      },
      "outputs": [],
      "source": [
        "img = cv.cvtColor(isolated_image, cv.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Freq Domain Analaysis**\n"
      ],
      "metadata": {
        "id": "NeNCuiYfhspm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXESJJAHkFoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6gNknb3kF8R"
      },
      "outputs": [],
      "source": [
        "view_index = 300\n",
        "\n",
        "\n",
        "def apply_high_pass_filter(input_fft, cutoff_radius, apply_gaussian=False):\n",
        "    high_pass_mask = ~generate_circle_mask(input_fft.shape, cutoff_radius)\n",
        "    if apply_gaussian:\n",
        "        high_pass_mask = cv.GaussianBlur(high_pass_mask, (21, 21), 0)\n",
        "\n",
        "    high_pass_mask[input_fft.shape[0]//2, input_fft.shape[1]//2] = 255\n",
        "    shifted_fft = np.fft.fftshift(input_fft)\n",
        "    filtered_fft = np.multiply(shifted_fft, high_pass_mask)\n",
        "    return process_shifted_fft(filtered_fft)\n",
        "\n",
        "def apply_low_pass_filter(input_fft, cutoff_radius, apply_gaussian=False):\n",
        "    low_pass_mask = generate_circle_mask(input_fft.shape, cutoff_radius)\n",
        "    if apply_gaussian:\n",
        "        low_pass_mask = cv.GaussianBlur(low_pass_mask, (21, 21), 0)\n",
        "    shifted_fft = np.fft.fftshift(input_fft)\n",
        "    filtered_fft = np.multiply(shifted_fft, low_pass_mask)\n",
        "    return process_shifted_fft(filtered_fft)\n",
        "\n",
        "\n",
        "\n",
        "def extract_intensity_values(image_data, selected_row=None, selected_col=None):\n",
        "    img_rows, img_cols = image_data.shape\n",
        "    if image_data is None:\n",
        "        raise ValueError(\"Image not found or unable to load!\")\n",
        "    if selected_row is None and selected_col is None:\n",
        "        selected_row = img_rows // 2\n",
        "    elif selected_row is not None and (selected_row < 0 or selected_row >= img_rows):\n",
        "        raise ValueError(f\"Row doesn't exist\")\n",
        "    elif selected_col is not None and (selected_col < 0 or selected_col >= img_cols):\n",
        "        raise ValueError(f\"Column doesn't exist\")\n",
        "    elif selected_row is not None:\n",
        "        intensity_values = image_data[selected_row, :]\n",
        "        x_values = np.arange(img_cols)\n",
        "        label_text = f\"Row {selected_row}\"\n",
        "    else:\n",
        "        intensity_values = image_data[:, selected_col]\n",
        "        x_values = np.arange(img_rows)\n",
        "        label_text = f\"Column {selected_col}\"\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(x_values, intensity_values, label=label_text)\n",
        "    plt.title('Time-Domain Representation of Pixel Intensities')\n",
        "    plt.xlabel('Pixel Index')\n",
        "    plt.ylabel('Intensity')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return intensity_values\n",
        "\n",
        "intensity_values = extract_intensity_values(img, view_index, view_index)\n",
        "\n",
        "def analyze_signal_peaks(signal_data, config_params):\n",
        "    if 'min_peak_height' not in config_params or config_params['min_peak_height'] is None:\n",
        "        raise ValueError(\"Height is needed\")\n",
        "\n",
        "    detected_peaks, _ = find_peaks(signal_data, height=config_params['min_peak_height'], distance=config_params['peak_distance'])\n",
        "\n",
        "    if len(detected_peaks) == 0:\n",
        "        print(\"Negative peak sequence\")\n",
        "        return {\n",
        "            'are_peaks_uniform': False,\n",
        "            'suggested_filter': None\n",
        "        }\n",
        "\n",
        "    peak_intervals = np.diff(detected_peaks)\n",
        "    peaks_uniform = len(peak_intervals) > 0 and np.allclose(peak_intervals, peak_intervals[0], atol=config_params['distance_tolerance'])\n",
        "\n",
        "\n",
        "    fft_result = np.fft.fft(signal_data)\n",
        "    fft_magnitude_values = np.abs(fft_result)\n",
        "    fft_freq_values = np.fft.fftfreq(len(signal_data), d=1/config_params['sampling_interval'])\n",
        "    positive_freq_values = fft_freq_values[:len(signal_data)//2]\n",
        "    positive_magnitude_values = fft_magnitude_values[:len(signal_data)//2]\n",
        "    freq_peak_indices, _ = find_peaks(positive_magnitude_values, height=np.mean(positive_magnitude_values))\n",
        "    dominant_frequencies = positive_freq_values[freq_peak_indices]\n",
        "    dominant_magnitudes = positive_magnitude_values[freq_peak_indices]\n",
        "\n",
        "    applied_filter_type = None\n",
        "    if dominant_frequencies.size > 0:\n",
        "        applied_filter_type = \"Low-pass\" if dominant_frequencies[0] * 10000 < 60 else \"High-pass\"\n",
        "    else:\n",
        "        applied_filter_type = \"Low-pass\"\n",
        "\n",
        "    return {\n",
        "        'are_peaks_uniform': peaks_uniform,\n",
        "        'suggested_filter': applied_filter_type\n",
        "    }\n",
        "\n",
        "wave_analysis_config = {\n",
        "    'min_peak_height': 145, 'peak_distance': 50,\n",
        "    'distance_tolerance': 6, 'sampling_interval': 1.0\n",
        "}\n",
        "\n",
        "analysis_results = analyze_signal_peaks(intensity_values, wave_analysis_config)\n",
        "\n",
        "\n",
        "\n",
        "def process_shifted_fft(shifted_fft_data):\n",
        "    inverse_fft = np.fft.ifft2(np.fft.ifftshift(shifted_fft_data))\n",
        "    magnitude_result = np.abs(inverse_fft)\n",
        "    return magnitude_result.astype(np.uint16)\n",
        "\n",
        "\n",
        "if analysis_results['are_peaks_uniform']:\n",
        "    fft_image = np.fft.fft2(img)\n",
        "    if analysis_results['suggested_filter'] == \"High-pass\":\n",
        "        processed_image = apply_high_pass_filter(fft_image, 20, apply_gaussian=False)\n",
        "    elif analysis_results['suggested_filter'] == \"Low-pass\":\n",
        "        processed_image = apply_low_pass_filter(fft_image, 125, apply_gaussian=True)\n",
        "\n",
        "    processed_image = np.abs(processed_image)\n",
        "    processed_image = np.uint8(255 * (processed_image / np.max(processed_image)))\n",
        "    if len(processed_image.shape) > 2:\n",
        "        processed_image = cv.cvtColor(processed_image, cv.COLOR_BGR2GRAY)\n",
        "    freq_fixed_img = processed_image[:, 50:-50]\n",
        "else:\n",
        "    freq_fixed_img = img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SC6mbtcZEIj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "if analysis_results['are_peaks_uniform']:\n",
        "    fft_image = np.fft.fft2(img)\n",
        "    if analysis_results['suggested_filter'] == \"High-pass\":\n",
        "        processed_image = apply_high_pass_filter(fft_image, 20, apply_gaussian=False)\n",
        "    elif analysis_results['suggested_filter'] == \"Low-pass\":\n",
        "        processed_image = apply_low_pass_filter(fft_image, 125, apply_gaussian=True)\n",
        "\n",
        "    processed_image = np.abs(processed_image)\n",
        "    processed_image = np.uint8(255 * (processed_image / np.max(processed_image)))\n",
        "    if len(processed_image.shape) > 2:\n",
        "        processed_image = cv.cvtColor(processed_image, cv.COLOR_BGR2GRAY)\n",
        "    freq_fixed_img = processed_image[:, 50:-50]\n",
        "else:\n",
        "    freq_fixed_img = img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8Ni-HArZEIk"
      },
      "source": [
        "**Apply Median Filter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnqoXinxZEIk"
      },
      "outputs": [],
      "source": [
        "\n",
        "##kernel = np.ones((3,1),np.float32)/2.5\n",
        "##noise_fixed_img = cv.filter2D(freq_fixed_img,-1,kernel)\n",
        "##display_image(noise_fixed_img, 'Median Blurred Image')\n",
        "\"\"\"\"\n",
        "median_blur = cv.medianBlur(freq_fixed_img, 9)\n",
        "display_image(median_blur, 'Median Blurred Image')\n",
        "\"\"\"\n",
        "\n",
        "##vertical_median_blur = cv.medianBlur(cv.blur(freq_fixed_img, (5, 5)), 3)\n",
        "##display_image(vertical_median_blur, 'Vertical Median Blurred Image')\n",
        "\n",
        "# Apply Morph Open to remove noise\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "opening = cv.morphologyEx(freq_fixed_img, cv.MORPH_CLOSE, kernel, iterations=1)\n",
        "display_image(opening, 'Morphological Opening')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PtOaYCuZEIk"
      },
      "source": [
        "**Thresholding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3ZyUNjUZEIk"
      },
      "outputs": [],
      "source": [
        "_, binary_img = cv.threshold(opening, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)\n",
        "display_image(binary_img, 'Binary Image')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPQtexb5ZEIk"
      },
      "source": [
        "**Fix Rotation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq5KkwtQZEIk"
      },
      "outputs": [],
      "source": [
        "def detect_and_rotate(image):\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv.findContours(image, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Filter contours based on area\n",
        "    all_contours = []\n",
        "    for contour in contours:\n",
        "        if cv.contourArea(contour) > 100:  # Only consider larger contours that could be part of the barcode\n",
        "            all_contours.append(contour)\n",
        "\n",
        "    # Combine all contours to analyze the overall bounding rectangle\n",
        "    combined_contour = np.vstack(all_contours)\n",
        "\n",
        "    # Get the minimum area rectangle around the combined contour\n",
        "    rect = cv.minAreaRect(combined_contour)\n",
        "    angle = rect[2]\n",
        "\n",
        "    # If the angle is not near zero, the barcode is rotated\n",
        "    if abs(angle) > 1:\n",
        "\n",
        "        # Adjust the rotation angle\n",
        "        if angle < -45:\n",
        "            angle = 90 + angle\n",
        "        elif angle > 45:\n",
        "            angle = angle - 90\n",
        "\n",
        "        # Compute the rotation matrix\n",
        "        # Get the center of the bounding rectangle\n",
        "        center = (int(rect[0][0]), int(rect[0][1]))\n",
        "\n",
        "        # Get the rotation matrix\n",
        "        rotation_matrix = cv.getRotationMatrix2D(center, angle, 1.0)\n",
        "\n",
        "        # Get the dimensions of the image\n",
        "        rows, cols = image.shape[:2]\n",
        "\n",
        "        # Rotate the image using warpAffine\n",
        "        rotated_image = cv.warpAffine(image, rotation_matrix, (cols, rows), flags=cv.INTER_CUBIC, borderMode=cv.BORDER_REPLICATE)\n",
        "\n",
        "        return rotated_image\n",
        "\n",
        "    else:\n",
        "        return image  # No rotation needed\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check and rotate the image if needed\n",
        "rotated_img = detect_and_rotate(binary_img)\n",
        "\n",
        "# Morph close to fill gaps\n",
        "kernel = np.ones((7, 1), np.uint8)\n",
        "closed_img = cv.morphologyEx(rotated_img, cv.MORPH_CLOSE, kernel, iterations=1)\n",
        "display_image(closed_img, 'Closed Image')\n",
        "\n",
        "display_image(cv.bitwise_not(rotated_img), 'Rotated Image')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASFJqZTBZEIk"
      },
      "source": [
        "**Morph Open**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T_q87eeZEIk"
      },
      "outputs": [],
      "source": [
        "vertical_kernel = np.ones((60, 1), np.uint8)\n",
        "opened_img = cv.morphologyEx(closed_img, cv.MORPH_OPEN, vertical_kernel, iterations=1)\n",
        "display_image(opened_img, 'Opened Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2dBToR9ZEIl"
      },
      "source": [
        "**Crop, Close, Dilate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTgPLXFnZEIl"
      },
      "outputs": [],
      "source": [
        "cropped_img, contour_img = crop_barcode3(opened_img)\n",
        "display_image(cv.bitwise_not(cropped_img), 'Cropped Image')\n",
        "\n",
        "# Close the cropped image\n",
        "kernel = np.ones((100, 1), np.uint8)\n",
        "closed_img = cv.morphologyEx(cropped_img, cv.MORPH_CLOSE, kernel, iterations=3)\n",
        "display_image(cv.bitwise_not(closed_img), 'Closed Image')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr8S0Z84ZEIl"
      },
      "source": [
        "**Decode**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1Ubz4tvZEIl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 0 means narrow, 1 means wide\n",
        "NARROW = \"0\"\n",
        "WIDE = \"1\"\n",
        "code11_widths = {\n",
        "    \"00110\": \"Stop/Start\",\n",
        "    \"10001\": \"1\",\n",
        "    \"01001\": \"2\",\n",
        "    \"11000\": \"3\",\n",
        "    \"00101\": \"4\",\n",
        "    \"10100\": \"5\",\n",
        "    \"01100\": \"6\",\n",
        "    \"00011\": \"7\",\n",
        "    \"10010\": \"8\",\n",
        "    \"10000\": \"9\",\n",
        "    \"00001\": \"0\",\n",
        "    \"00100\": \"-\",\n",
        "}\n",
        "\n",
        "# Threshold the cropped image\n",
        "mean = cv.bitwise_not(closed_img).mean(axis=0)  # Column-wise mean\n",
        "mean = np.where(mean <= 127, 1, 0)  # Black or White\n",
        "\n",
        "print(\"Mean Array:\", mean)  # Check the binary output\n",
        "\n",
        "# Convert to string of pixels in order to loop over it\n",
        "pixels = list(''.join(mean.astype(np.uint8).astype(str)))\n",
        "\n",
        "# Remove up to 15 zeros from the start\n",
        "trim_count = 0\n",
        "while len(pixels) > 0 and trim_count < 150 and pixels[0] == \"0\":\n",
        "    pixels.pop(0)\n",
        "    trim_count += 1\n",
        "\n",
        "# Remove up to 15 zeros from the end\n",
        "trim_count = 0\n",
        "while len(pixels) > 0 and trim_count < 150 and pixels[-1] == \"0\":\n",
        "    pixels.pop()\n",
        "    trim_count += 1\n",
        "\n",
        "# Print after trimming\n",
        "print(\"Trimmed Mean Array:\", pixels)\n",
        "\n",
        "# Convert list back to string\n",
        "pixels = ''.join(pixels)\n",
        "\n",
        "# Need to figure out how many pixels represent a narrow bar\n",
        "narrow_bar_size = 0\n",
        "for pixel in pixels:\n",
        "    if pixel == \"1\":\n",
        "        narrow_bar_size += 1\n",
        "    else:\n",
        "        break\n",
        "print(\"Narrow Bar Size:\", narrow_bar_size)\n",
        "\n",
        "wide_bar_size = narrow_bar_size * 2\n",
        "\n",
        "digits = []\n",
        "pixel_index = 0\n",
        "current_digit_widths = \"\"\n",
        "skip_next = False\n",
        "\n",
        "while pixel_index < len(pixels):\n",
        "\n",
        "    if skip_next:\n",
        "        pixel_index += narrow_bar_size\n",
        "        skip_next = False\n",
        "        continue\n",
        "\n",
        "    count = 1\n",
        "    try:\n",
        "        while pixels[pixel_index] == pixels[pixel_index + 1]:\n",
        "            count += 1\n",
        "            pixel_index += 1\n",
        "    except:\n",
        "        pass\n",
        "    pixel_index += 1\n",
        "\n",
        "    # Determine if the bar width is narrow or wide\n",
        "    if 3 <= count <= 5:\n",
        "        current_digit_widths += NARROW\n",
        "    elif 7 <= count <= 9:\n",
        "        current_digit_widths += WIDE\n",
        "\n",
        "    if current_digit_widths in code11_widths:\n",
        "        digits.append(code11_widths[current_digit_widths])\n",
        "        current_digit_widths = \"\"\n",
        "        skip_next = True  # Next iteration will be a separator, so skip it\n",
        "\n",
        "print(digits)\n",
        "\n",
        "\n",
        "if (image_number == 1):\n",
        "    print(\"Expected Result: 1234567890-\")\n",
        "elif (image_number == 2):\n",
        "    print(\"Expected Result: 104-116-116\")\n",
        "elif (image_number == 3):\n",
        "    print(\"Expected Result: 112-115-58-\")\n",
        "elif (image_number == 4):\n",
        "    print(\"Expected Result: -47-47-121-\")\n",
        "elif (image_number == 5):\n",
        "    print(\"Expected Result: 111-117-116\")\n",
        "elif (image_number == 6):\n",
        "    print(\"Expected Result: -117-46-98-\")\n",
        "elif (image_number == 7):\n",
        "    print(\"Expected Result: 101-47-100-\")\n",
        "elif (image_number == 8):\n",
        "    print(\"Expected Result: 113-119-52-\")\n",
        "elif (image_number == 9):\n",
        "    print(\"Expected Result: 119-57-119-\")\n",
        "elif (image_number == 10):\n",
        "    print(\"Expected Result: 103-120-99-\")\n",
        "elif (image_number == 11):\n",
        "    print(\"Expected Result: 113-47-35-35\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}